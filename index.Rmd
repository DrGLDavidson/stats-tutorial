---
title: "Statistics Tutorial"
author: "Gabrielle Davidson, School of Biological Sciences, University of East Anglia"
date: "`r Sys.Date()`"
output: 
  html_document:
    mathjax: "default"
    toc: true
    number_sections: true
---

# Getting started

Welcome to the statistics tutorial for datasets typically encountered in the Davidson Lab, School of Biological Sciences, University of East Anglia. This guide will walk you through selecting the appropriate statistical model for your data, formulating the model syntax and variables, testing model assumptions, improving model fit, and performing “model selection.” We will also cover commonly used graphical representations for different types of data.

## Install and load R package dependencies 
```{r eval=FALSE}
# Install the required packages (if not already installed)
required_packages <- c("tidyverse", "lme4", "MASS", "nlme", "lmerTest", "MuMIn", "ggpubr", "performance")

# Install packages that aren't already installed
install_if_needed <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(install_if_needed)) install.packages(install_if_needed)

You can also install each manually using the function install.packages("nameOfPackage")

# Load the packages after installation
library(tidyverse)   # A collection of R packages for data science
library(lme4)        # Provides tools for fitting linear and generalized linear mixed-effects models (GLMMs).
library(MASS)        # A large collection of statistical functions, with a focus on generalized linear models (GLMs).
library(nlme)        # Mixed-effects models, and can fit both linear and nonlinear mixed-effects models (U-shaped, sigmoidal, exponential). Model diagnostic tools. 
library(lmerTest)    # Adds p-values to lme4 models
library(performance) # checks for colinearity
library(MuMIn)       # Model selection & averaging
library(ggplot2)     # Data visualization
library(ggpubr)      # Enhanced ggplot2 functions
```

## Troubleshooting install issues
If you have trouble installing packages try the following: 
* Read the content of the error warning
* Does the package you are installing have dependencies? the error may say "x package not found". Install that package using ```install.packages("nameofpackage")```
* Search the error online
* Search alternative ways to install the package. Sometimes vignettes for the package have direct links you can use for installation, rather than using ```install.packages()```

# Workflow

```{r out.width="25%", out.height="25%", echo=FALSE, fig.align="center"}
knitr::include_graphics("F:/RWorkspace/GitHub/stats-tutorial/data/stats_workflows.jpg")

```

# Defining variables

Some terminology can be used interchangeably, here is a breakdown. 

```{r, echo=FALSE, results="asis"}
# Creating a nicely formatted table in R Markdown with borders and shading

library(knitr)
library(kableExtra)

# Define the table content
terms_table <- data.frame(
  Term = c("Predictor", "Outcome", "Explanatory", "Response", "Fixed Effect"),
  Description = c(
    "Independent variable(s) used to explain or predict the dependent variable.",
    "The dependent variable, whose variation is being explained or predicted by the predictors.",
    "Similar to 'predictor', refers to the variable that explains or influences the dependent variable.",
    "The dependent variable in a study or experiment, often used in regression models.",
    "A variable that is considered to have a fixed influence on the dependent variable in a model, often contrasted with random effects."
  )
)

# Create the table with nice shading and borders
kable(terms_table, col.names = c("Term", "Description"), caption = "Common Terms for Independent and Dependent Variables") %>%
  kable_styling("striped", full_width = FALSE, position = "center") %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, background = "#D9EAD3", bold = TRUE)  # Set header row background color
```


```{r, echo=FALSE, results="asis"}
# Creating a nicely formatted table with variable types and their descriptions

# Define the table content
variable_types_table <- data.frame(
  Variable_Type = c("Continuous (Gaussian)", "Count", "Binomial (Success/Failure)", "Categorical"),
  Description = c(
    "A variable that can take any value within a range, typically measured on a continuous scale (e.g., height, weight).",
    "A variable that represents the number of occurrences of an event, typically non-negative integers (e.g., number of birds observed).",
    "A variable with two possible outcomes (e.g., success/failure, yes/no), or quantified as proportion data from two possible outcomes (e.g. 4 out of 10 correct).",
    "A variable with categories or levels that represent distinct groups or classes (e.g., species, treatment groups)."
  )
)

# Create the table with nice shading and borders
kable(variable_types_table, col.names = c("Variable Type", "Description"), caption = "Types of Response and Predictor Variables") %>%
  kable_styling("striped", full_width = FALSE, position = "center") %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, background = "#D9EAD3", bold = TRUE)  # Set header row background color
```

# Choosing an appropriate statistical test

## Regression models

LMs (Linear Models), GLMs (Generalized Linear Models), and GLMMs (Generalized Linear Mixed Models) are all part of a broad collection of regression models. Each of these models is used to examine relationships between dependent and independent variables, but **they differ in their assumptions, data requirements, and flexibility**.

### Linear Models (LMs)
LMs are the simplest type of regression models. They model the relationship between a dependent variable (response) and one or more independent variables (predictors) using a linear equation.

The model can be written as: 
$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \epsilon
$$

Where:
- \( Y \) is the dependent variable, and specifically a continuous variable (i.e. gaussian distribution).
- \( \beta_0 \) is the intercept.
- \( \beta_1, \beta_2, \dots \) are the coefficients for the independent variables \( X_1, X_2, \dots \).
- \( \epsilon \) is the error term.

### Linear Mixed Models (LMMs)

The Linear Mixed Model (LMM) is an extension of the linear model that includes **random effects** to account for correlations within grouped or hierarchical data. These might include repeated measures (i.e. data points collected) from the same individuals, or repeated measures (i.e. data points collected) from the same geographical site. 

The model can be written as:

$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + b_0 + \epsilon
$$

Where:
- \( Y \) is the dependent variable, and specifically a continuous variable (i.e. gaussian distribution).
- \( \beta_0 \) is the **fixed intercept**.
- \( \beta_1, \beta_2, \dots \) are the **fixed effect coefficients** for the independent variables \( X_1, X_2, \dots \).
- \( b_0 \) is the **random intercept** associated with each group, representing the deviation of each group’s intercept from the overall intercept. It is assumed to follow a normal distribution with mean 0 and variance \( \sigma^2_b \), i.e., \( b_0 \sim \mathcal{N}(0, \sigma^2_b) \).
- \( \epsilon \sim \mathcal{N}(0, \sigma^2) \) is the **residual error term**, assumed to be normally distributed with mean 0 and variance \( \sigma^2 \).

**What does it mean?** 
- If modeling data with repeated measurements from subjects, \( b_0 \) accounts for individual-specific variations in the intercept.
- The fixed effects (\( \beta_0, \beta_1, \dots \)) represent the overall average relationship between predictors and the outcome, while the random effects capture variation at the group level.

This formulation allows the model to handle **correlated data** within groups, such as multiple measurements from the same subject or repeated observations from different locations.

### Generalised Linear Models (GLMs)

GLMs extend linear models by allowing for response variables that have distributions other than the normal distribution (e.g., binomial, Poisson).

They introduce the concept of a link function to model the relationship between the predictors and the mean of the response variable.

GLMs are used when the response variable is categorical (e.g., logistic regression for binary outcomes) or count data (e.g., Poisson regression).

The model can be written as: 
$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \epsilon
$$

Where:
- \( Y \) is the dependent variable which can follow distributions such as **binary** (e.g., for logistic regression) or **count** (e.g., for Poisson regression).
- \( \beta_0 \) is the intercept.
- \( \beta_1, \beta_2, \dots \) are the coefficients for the independent variables \( X_1, X_2, \dots \).
- \( \epsilon \) is the error term.

### Generalised Linear Mixed Models (GLMMs)

The Generalized Linear Mixed Model (GLMM) extends the Generalized Linear Model (GLM) by incorporating **random effects**, which allow for hierarchical or grouped data structures.

The model can be written as:

$$
Y = g^{-1} \left( \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + b_0 + \epsilon \right)
$$

Where:
- \( Y \) is the dependent variable which can follow distributions such as **binary** (e.g., for logistic regression) or **count** (e.g., for Poisson regression).
- \( g^{-1} \) is the **inverse link function**, mapping the linear predictor to the expected value of \( Y \).
- \( \beta_0 \) is the **fixed intercept**.
- \( \beta_1, \beta_2, \dots \) are the **fixed effect coefficients** for the independent variables \( X_1, X_2, \dots \).
- \( b_0 \sim \mathcal{N}(0, \sigma^2_b) \) is the **random intercept**, assumed to follow a normal distribution with mean 0 and variance \( \sigma^2_b \).
- \( \epsilon \sim \mathcal{N}(0, \sigma^2) \) is the **residual error term**.

**What does it mean?**
- If modeling repeated measures, \( b_0 \) represents variation in the intercept for different individuals.
- If modeling data from multiple locations, \( b_0 \) accounts for location-specific differences.

This formulation allows the model to **capture dependencies** within grouped data while retaining the flexibility of a generalized linear framework.

---

### Selecting the appropriate regression model for your data

Simply put, follow the workflow (Figure 1) to select the right regression model for your data.


```{r out.width="75%", out.height="75%", echo=FALSE, fig.align="center"}
knitr::include_graphics("F:/RWorkspace/GitHub/stats-tutorial/data/regression_workflow.tif")

```
<center>
Figure 1. Regression model selection workflow
</center>

### Model Assumptions for LM, LMM, GLM, and GLMM

| **Model Type**            | **Homoscedasticity (Homogeneity of Variance)** | **Normality of Residuals** | **Linearity** | **Independence of Observations/Errors** | **Definition**                                                                                                                                   |
|---------------------------:|:-----------------------------------------------:|:----------------------------:|:---------------:|:------------------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------|
| **Linear Model (LM)**      | Yes                                           | Yes                        | Yes           | Yes                                      | Homoscedasticity assumes the variance of the residuals is constant across all levels of the predictors. Normality assumes the residuals are normally distributed. Linearity assumes a straight-line relationship between predictors and the response variable. Independence assumes observations (or errors) are not correlated with each other.                     |
| **Linear Mixed Model (LMM)** | Yes                                           | Yes                        | Yes           | Yes                                      |  Homoscedasticity applies to residuals after accounting for random effects. Normality applies to both residuals and random effects. Linearity and independence assumptions are similar to LM.|
| **Generalized Linear Model (GLM)** | No                                           | No                         | Yes           | No                                       | GLMs do not assume homoscedasticity; variance is determined by the distribution of the response variable. Normality is not assumed, as the response follows the appropriate distribution. Linearity still applies in terms of the linear predictor. Independence of observations is assumed.|
| **Generalized Linear Mixed Model (GLMM)** | No                                           | No                         | Yes           | No                                       | GLMMs do not assume homoscedasticity or normality. The variance depends on the response distribution, and errors follow the chosen family (e.g., Poisson, binomial). Linearity applies to the linear predictor, but observations are not assumed independent due to random effects.|

**Summary of assumptions**

**Homoscedasticity (Homogeneity of Variance)**: This assumption states that the variance of the residuals should be constant across all levels of the independent variable(s). In the context of linear and linear mixed models, the residuals should exhibit consistent spread across the predictor values.

**Normality of Residuals**: This assumption holds that the residuals (or errors) from the model should follow a normal distribution. For linear models, this is important for valid hypothesis testing and constructing confidence intervals. In mixed models, it applies to both residuals and random effects.

**Linearity**: This assumption states that there is a linear relationship between the independent variable(s) and the dependent variable. For linear models, the effect of each predictor on the outcome is assumed to be linear, meaning a unit change in the predictor corresponds to a fixed change in the outcome.

**Independence of Observations/Errors**: This assumption holds that the residuals (errors) are independent of one another. In linear and mixed models, this means that one observation (or error) is not correlated with another, ensuring the independence of the data points used in the model.


## Principal Component Analysis (PCA)

Principal Component Analysis (PCA) is a **dimensionality reduction** technique used to simplify large datasets by transforming the data into a smaller set of uncorrelated variables called **principal components**. These components explain the variance in the original data, with the first principal component explaining the greatest variance.

For example, imagine you have a dataset containing scores from an intelligence test, where multiple measures (such as memory, reasoning, problem-solving, etc.) are recorded. These measures may be correlated, as they all assess aspects of cognitive ability. PCA can be used to combine these correlated variables into a smaller number of principal components, capturing the main variation in the data without losing significant information.

The PCA model can be written as:

$$
\mathbf{X} = \mathbf{T} \mathbf{P}^T + \mathbf{E}
$$

Where:
- \( \mathbf{X} \) is the original data matrix (with variables as columns and observations as rows).
- \( \mathbf{T} \) is the **scores matrix**, where each row represents the transformed data in terms of the principal components.
- \( \mathbf{P} \) is the **loading matrix**, representing the eigenvectors (directions) of the original data that correspond to the principal components.
- \( \mathbf{E} \) is the **residual matrix**, representing the part of the original data that cannot be explained by the principal components.

**What does it mean?**
- PCA identifies the axes (principal components) that maximize the variance in the data.
- The first principal component \( \mathbf{t}_1 \) explains the greatest variance, while subsequent components \( \mathbf{t}_2, \mathbf{t}_3, \dots \) explain progressively less variance.
- The loadings matrix \( \mathbf{P} \) shows how each original variable contributes to the principal components.

PCA is commonly used for:
- **Data reduction**, where a smaller number of principal components are used to represent the data with minimal loss of information.
- **Visualisation** of high-dimensional data, typically in 2D or 3D plots, by using the first two or three principal components.

---

# Regression models in R

## Input data format

Your dataframe should be in long format (Table 1) where:

Each **row** represents a single observation (i.e., the unit of analysis).  
Columns contain variables, including:  
**Response variable** (e.g., count, presence/absence, continuous measure).  
**Fixed effects** (e.g., treatment, environmental variables).  
**Random effects** (e.g., subject ID, site, time point).  

Categorical variables should be coded appropriately (e.g., factors, dummy variables). Categorical variables will have 2 or more categories, also known as **levels**. In the types of regressions taught in this tutorial, the functions will automatically define a reference level alphabetically. Therefore in a category like age, with levels adult and juvenile, the reference category will be adult and outputs will be described as juvenile *relative to* adult.  
Numeric variables should be scaled if necessary for model convergence.  

```{r, echo=FALSE, message=FALSE}
library(knitr)
library(kableExtra)

# Example data
df <- data.frame(
  Subject_ID = c("A", "A", "B", "B"),
  Time = c(1, 2, 1, 2),
  Treatment = c("Control", "Control", "Treatment", "Treatment"),
  Response = c(5.2, 6.1, 8.3, 7.9),
  Site = c("X", "X", "Y", "Y")
)

# Styled table
kable(df, format = "html", caption = "Example of long-format data for regression models") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "bordered"))
```

## Basic model code syntax

The R package, the function and its syntax (i.e. the way you write the model formula) depends on the type of model you are running. 

**LM syntax**

```model <- lm(response ~ predictor1 + predictor2, data = your_data)```

**LMM syntax**

```model <- lmer(response ~ predictor1 + (1|group), data = your_data, family = gaussian)```

**GLM syntax**

```model <- glm(response ~ predictor1 + predictor2, family = binomial, data = your_data)```

```model <- glm(response ~ predictor1 + predictor2, family = poisson, data = your_data)```

**GLMM syntax**

```model <- glmer(response ~ predictor1 + predictor2 + (1 | group), family = binomial, data = your_data)```

GLMMS can be run using a slightly different package that can handle non-linear structures and provides AIC and BIC output scores:  

```model <- lme(response ~ predictor1 + predictor2, random = ~ 1 | group, data = your_data)```

where ```reponse``` is your dependent variable, ```predictor1``` and ```predictor2``` are your dependent variables, also known as **fixed effects**, and ```group``` is your repeated measures, such as individual or site, also known as **random effects**.

## Including interaction terms in your model code syntax

Interactions in statistical models allow you to explore how the relationship between one predictor and the outcome changes depending on the value of another predictor.

Instead of simply including main fixed effects ```response ~ predictor1 + predictor2``` , to test an interaction between fixed effects, change the syntax by replacing the ```+``` with a ```*```  ```response ~ predictor1*predictor2```

**Example**
Imagine you measured the cognition of birds, but the birds were of different sex and age; including an interaction in your model allows you to explore how the relationship between age and cognition changes depending on the bird's sex.

For example, age may positively affect cognition in males but not in females. older males may have better cognition than younger males. or perhaps older females might have a lower cognition compared to younger females, perhaps due to differences in reproductive energy allocation or other biological factors.

Ignoring the interaction could lead to incorrect inferences. For instance, a model without the interaction term might incorrectly assume that age affects males and females the same way.

That being said, be sure to only include interaction terms if you have an a priori reason to test the interaction, based on existing literature, ecological theory or speculations based on observations. 

---

## Example dataset and models

We will perform some example analyses in R. They are a guide and starting point and do not cover all model types, but the concepts are the same. You will need to apply these concepts flexibly, according to the type of model that is appropriate for your data, and the variables included. Your dataframe, variable names and number of variables and interactions will likely differ, and will need to be substituted according to the syntax described above.  

We begin by creating some mock data. When it comes to running your own analyses, you would load and name your dataframe into your R global environment. It will then be available to call within the regression function, specifying the name you gave your dataframe. In the example dataset here, we are creating a dataframe call bird_data. 

```{r}
set.seed(123)  # Ensures the random code is reproducible 

# Number of rows
n <- 100

# Create mock data
bird_data <- data.frame(
  # Randomly assign age (adult or juvenile)
  age = factor(sample(c("adult", "juvenile"), n, replace = TRUE)),
  
  # Randomly assign sex (male or female)
  sex = factor(sample(c("male", "female"), n, replace = TRUE)),
  
  # Randomly assign site (3 different sites)
  site = factor(sample(1:3, n, replace = TRUE)),
  
  # Generate continuous body_size data (e.g., normally distributed)
  body_size = rnorm(n, mean = 50, sd = 10)  # Mean = 50, SD = 10
)

# Now, generate cognition based on the predictors (age, sex, body_size) and their interaction
# We'll add some noise with rnorm() to simulate data
bird_data$cognition <- with(bird_data, 
                            10 + 3*(age == "juvenile") + 2*(sex == "male") + 
                              1.5*(age == "juvenile" & sex == "male") + 0.05*body_size + 
                              rnorm(n, mean = 0, sd = 5))  # Add random noise

```

```{r}
# Check the first few rows of the dataset
head(bird_data)
```

### LMM gaussian distribution with random effects: 

```{r, warning = FALSE, message= FALSE}
# Run the model
library(lme4) # For the lmer() function
library(lmerTest) # To generate p-values

# Fit the linear mixed model with age, sex, body_size, and their interaction
model <- lmer(cognition ~ age * sex + body_size + (1 | site), data = bird_data)
```

Generate the statistical output of your model
```{r}
# Summary of the model
summary(model)
```

### LMM model output and interpretation 

The key details to pay attention to are the fixed effects (Table 2) and random effects tables (Table 3). 

**Estimate**:

The model’s best guess at the effect size of each predictor. The intercept in a linear model represents the baseline category, which is determined by the reference levels of categorical predictors. In this case, adults (age) and female (sex) are the baseline reference categories (i.e. what juveniles and males are compared to, respectively). The baseline category is determined by the model based on *alphabetical order*.  
**Intercept** (12.99): The estimated cognition score for an adult female with body size = 0 (baseline category).  
**Age (juvenile)** = 3.25: Juveniles have, on average, a 3.25-point higher cognition score than adults (when holding other factors constant). This is statistically significant.  
**Sex (male)** = 1.98: Although males have a slightly higher cognition score than females, the effect is not statistically significant.  
**Body size** = -0.0089: Body size does not predict cognition in this model.  
**Interaction (agejuvenile:sexmale)** = 0.71: The additional effect of being both juvenile and male is not significant.

**Standard Error (SE)**:

Measures the uncertainty around each estimate. Larger SE means less confidence in the estimate.

**Degrees of Freedom (df)**:

Degrees of freedom (df) determine how much information is available to estimate model parameters and conduct significance tests, it takes into account sample size and fixed and random effects. It's used to calculate the t-value and p-value. 

**t-value**:

Computed as Estimate / SE. Higher t-values indicate stronger evidence that the effect is different from zero. The sign of the t-value indicates the direction of the relationship (i.e. positive or negative for categorical values; greater than or less than the reference category)

**p-value**:

Measures the probability that the observed effect happened by chance.
Thresholds:

<0.10: non-significant trend (.)

<0.05: Significant (*)

<0.01: Very significant (**)

<0.001: Highly significant (***)

```{r, echo = FALSE}
library(knitr)
library(kableExtra)

# Fixed Effects Table
fixed_effects <- data.frame(
  Term = c("(Intercept)", "age (juvenile)", "sex (male)", "body size", "age × sex interaction"),
  Estimate = c(12.99, 3.25, 1.98, -0.0089, 0.71),
  `Std. Error` = c(2.45, 1.34, 1.30, 0.045, 1.98),
  df = c(84.69, 93.38, 94.16, 94.74, 94.20),
  `t value` = c(5.30, 2.42, 1.53, -0.198, 0.357),
  `p value` = c(9.07e-07, 0.0173, 0.1304, 0.8434, 0.7221)
)

kable(fixed_effects, digits = 3, caption = "Table 2: Fixed Effects from LMM") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "bordered"))
```

The random effects tell us how much variation is explained by the random effects and how much variation remains unexplained by the model. 

**Site (random intercept variance = 0.12)**: Suggests only a small amount of variation in cognition is due to site differences.

**Residual variance (23.77)**: The amount of variability left unexplained by the model.

```{r, echo = FALSE}
# Random Effects Table
random_effects <- data.frame(
  Group = c("Site", "Residual"),
  Name = c("(Intercept)", "-"),
  Variance = c(0.12, 23.77),
  `Std. Dev.` = c(0.35, 4.88)
)

kable(random_effects, digits = 3, caption = "Table 3: Random Effects from LMM") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "bordered"))
```


### GLMM binomial distribution with random effects 
```{r}
# Create a binary variable for proportion of correct choices (e.g., cognition > 15 is correct, otherwise incorrect)
bird_data$correct_choice <- ifelse(bird_data$cognition > 15, 1, 0)

head(bird_data)
```

```{r}
# Run the model
# Fit a mixed-effects logistic regression model
model2 <- glmer(correct_choice ~ age * sex + body_size + (1 | site), family = binomial(link = "logit"), data = bird_data)
```

Generate the statistical output of your model
```{r}
# Check the summary of the model
summary(model2)
```

### GLMM model output and interpretation 
The model output is similar to that of an LMM, except that the test statistic is a z-value, and degrees of freedom cannot be calculated. Because of this, glmer will not normally return p-values, which is why lmerTest is loaded as it estimates p values based on the z-value. As a rule of thumb, is the absolute value of z-value (or indeed t-value) is 2.00 or greater, the p-value will be statistically significant. 

In this example a warning about singular fit was returned. This is because no variance was explained by site in this model. 

There is also a non-significant trend for juvenile birds. Also notable is that there is no significant interaction, and therefore this raises the question of whether we should remove that interaction.

### Interactions: to include or not to include?

Including non-significant terms increases noise. Sometimes models can be packed so full of terms and interactions that they are overfit and fail to converge. More parameters make the model more complex without improving accuracy. Unnecessary interactions can lead to higher standard errors and less precise estimates for other terms.Every added predictor consumes df, reducing statistical power for detecting real effects. Removing non-significant interactions frees up df, improving estimates of main effects. One school of thought is to adopt parsimony: The best model is the simplest one that adequately explains the data. This rationale applies not just to interactions, but also main effects. 

To demonstrate this, run the previous model without the interaction term

```{r}
# Run the model
# Fit a mixed-effects logistic regression model without the interaction term
model3 <- glmer(correct_choice ~ age + sex + body_size + (1 | site), family = binomial(link = "logit"), data = bird_data)
summary(model3)
```

Without the interaction term, males have significantly higher cognition than females, and there is a trend for juveniles to have better cognition than adults. 

## Checking model assumptions

Model assumptions must be checked and reported in methods/results.

### Normality and homogeniety of residuals
In this section, we will apply two common transformations to the response variable (`cognition`): the **log transformation** and the **square root transformation**. These transformations can help stabilize variance and improve model fit. We will then assess the residuals from the different models to determine which, if any, transformation fits best.
To visualise **normality of residuals** we assess which plot shows datapoints that are best aligned with (tightly fit against) the solid regression line. 
to visualise **homogeneity of residuals**, we are looking for the plot where the datapoints are more randomly distributed (i.e. no clumping).

```{r}
# Apply log transformation
bird_data$cognition_log <- log(bird_data$cognition + 1)  # log(x+1) to avoid log(0)

# Apply square root transformation
bird_data$cognition_sqrt <- sqrt(bird_data$cognition)

# Fit models for raw, log-transformed, and square root-transformed data
model_raw <- lmer(cognition ~ age * sex + body_size + (1 | site), data = bird_data)
model_log <- lmer(cognition_log ~ age * sex + body_size + (1 | site), data = bird_data)
model_sqrt <- lmer(cognition_sqrt ~ age * sex + body_size + (1 | site), data = bird_data)

# Check residuals for each model
residuals_raw <- residuals(model_raw)
residuals_log <- residuals(model_log)
residuals_sqrt <- residuals(model_sqrt)

# Check normality of residuals using Q-Q plots
par(mfrow = c(1, 3))  # Set up a 1x3 layout for the plots
qqnorm(residuals_raw, main = "Raw Data")
qqline(residuals_raw)

qqnorm(residuals_log, main = "Log-transformed Data")
qqline(residuals_log)

qqnorm(residuals_sqrt, main = "Square Root-transformed Data")
qqline(residuals_sqrt)

# Reset layout
par(mfrow = c(1, 1))

# Plot residuals vs fitted values for homogeneity of variance
par(mfrow = c(1, 3))  # Set up a 1x3 layout for the plots
plot(fitted(model_raw), residuals_raw, main = "Raw Data", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")

plot(fitted(model_log), residuals_log, main = "Log-transformed Data", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")

plot(fitted(model_sqrt), residuals_sqrt, main = "Square Root-transformed Data", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "red")

# Reset layout
par(mfrow = c(1, 1))
```

Having reviewed these plots, the raw data is the best fit, there is no need to transform the response variable. 

### Colinearity 

Next we will test for colinearity between predictor variables by calculating **Variance Inflation Factor (VIF)**. ```check_collinearity()``` evaluates the extent of multicollinearity between predictors in linear, generalised, and mixed models, flagging variables that may be highly correlated and affect model estimates.

VIF = 1: No correlation with other predictors.

1 < VIF < 5: Moderate correlation, generally considered acceptable.

VIF > 5: Indicates potentially problematic multicollinearity, suggesting that predictors are highly correlated.

VIF > 10: Very high multicollinearity, which can severely distort model estimates. You should consider removing or combining predictors (see PCA) to address this issue.

```{r, message = FALSE}
library(performance)

check_collinearity(model_raw)

```

The 95% confidence interval around the VIF estimate gives the range of VIF values based on sampling variability.
If the standard Error (SE) is large, it indicates that multicollinearity is inflating the standard error of the coefficient, which makes it harder to detect a true effect of that predictor
Tolerance is the inverse of VIF. A value close to 1 inidicates little to no multicollinearity. A tolerance below 0.1 suggests multicollinearity. The output also gives the 95% CI around the tolenrence.

Our data shows no collinearity, so we can proceed with the analysis as is. 

---

## Model selection 

There are many methods for simplifying models by removing predictor terms. This is known as "model selection". The best model selection method depends on who you speak to, and current trends. 

**Summary of Model Selection Methods**

| Method | Best for | Advantages | Disadvantages |
|--------|---------|------------|---------------|
| **LRT** | Hypothesis testing, mixed models | Compares model fit rigorously | Requires nested models, sensitive to sample size |
| **AIC** | Model selection, avoiding overfitting | Penalises complexity, allows non-nested comparisons | No hypothesis testing, sensitive to small sample sizes |
| **p-values** | Quick significance check | Easy to interpret, widely used | Ignores overall model fit, affected by sample size |

**Recommendations:**  
Use **LRT** if testing a specific hypothesis about an effect.  
Use **AIC** for overall model selection and avoiding overfitting.  
Use **p-values** for quick checks, but don’t rely on them alone.  


### Likelihood Ratio Test (LRT)

The **Likelihood Ratio Test (LRT)** compares two **nested models** (one with and one without the term of interest) by evaluating whether removing the term significantly worsens model fit.

LRT Formula

\[
LRT\ statistic = -2 \times (\log \text{Likelihood of Reduced Model} - \log \text{Likelihood of Full Model})
\]

If the LRT statistic follows a **χ² distribution**, we can compute a p-value to determine if removing the term significantly worsens the model.

In this example, the p-value is 0.72, therefore the reduced model is not any better than the full model. Keep the full model. 

```{r lrt_example, message = FALSE}
library(lme4)
library(lmerTest)

# Full model (with interaction)
full_model <- lmer(cognition ~ age * sex + body_size + (1 | site), data = bird_data)

# Reduced model (without interaction)
reduced_model <- lmer(cognition ~ age + sex + body_size + (1 | site), data = bird_data)

# LRT comparison
anova(reduced_model, full_model)
```

---

### Akaike Information Criterion (AIC) Comparison

The **Akaike Information Criterion (AIC)** balances model fit and complexity:

\[
AIC = -2 \times \log \text{Likelihood} + 2K
\]

where \( K \) is the number of estimated parameters. **Lower AIC values indicate better models**.

Example in R:

```{r aic_example}
AIC(full_model, reduced_model)
```

- If **ΔAIC < 2**, the models are considered equivalent.
- If **ΔAIC > 2**, the model with higher AIC is worse.

---

### p-values to perform stepwise elimination

Start with a full model, then remove non-significant interactions first, followed by non-significant main effects (unless they are needed for interpretability). This used to be very popular, but is hardly used now. 

---

## AIC Model selection with model averaging

The order in which you remove terms can affect the output. Therefore the more thorough method for models with several terms is to run every combination of terms present/removed/as interactions. Luckily there are pacakges that can do this for us to automate the process and tell us which models have the lowest AIC values, and if this is greater or less than 2 units (we consider a minimum of 2 units necessary for it to be a better model fit). 

**Global model**: Also known as Full Model. One in which all terms and interactions are included.  
**Top model**: The model with the lowest AIC score.  
**Averaged model**: when more than one model are > 2 AIC units than other models, but < 2 AIC units relative to one another. In otherwords, there are multiple "top models", and so they must come to a combined consensus. 


```{r, warning = FALSE}
library(lme4)
library(lmerTest)
library(MuMIn)  

# Full model (with interaction)
global_model <- glmer(correct_choice ~ age*sex + body_size + (1 | site), family = binomial(link = "logit"), data = bird_data, na.action=na.fail) #must include na.action=na.fail for dredge()

dd<-dredge(global_model, evaluate=TRUE, rank=AICc) # this using AICc for ranking models, where AICc corrects for small sample sizes
dd

```

**TIP:** 
If there is a term you want to be retained for some biological/hypothesis testing justification, you can specify this using the ```subset()``` argument:

``` dd<-dredge(global_model, subset= ~age, evaluate=TRUE, rank=AICc)```

This above output shows us a model table. 
Each row represents a model variation, with different combinations of predictor variables (age, sex, body_size, and their interaction age:sex). 
The columns indicate:  
(Int): Intercept estimate.  
age, sex, body_size, age:sex: Whether each predictor is included (+ for included, - for excluded).

We can subset these models to include the top models with AICc scores that are <2 units. 
**Note that this can sometimes return nothing if there are no model better than the others**  

In this case, there are three top models. One which includes both sex and age as interactions, one that includes sex and age as main effects only, and one that only includes sex. 

```{r}
ddAIC_S<-subset(dd, delta < 2)
ddAIC_S
```

Next we perform model averaging, which will take these three top models to generate an output that can be reported, which considers model types as equivalently well-fit

```{r}
ddMAc<-model.avg(ddAIC_S, subset= delta <2)
summary(ddMAc)
```

### Choosing between full and conditional model averaging

When using **model averaging**, you have two options for computing the estimates:  

1. **Full Average:** Includes all candidate models, even if a term is absent in some models. When a term is missing, it is treated as zero.  
2. **Conditional Average:** Only includes models where a term appears, ignoring models where the term is absent.  

---

**Key Differences and When to Use Each**  

| Approach             | How It Works                                                                 | Pros                                                | Cons                                                |
|----------------------|------------------------------------------------------------------------------|-----------------------------------------------------|-----------------------------------------------------|
| **Full Average**      | Assigns a coefficient of **zero** to models where a predictor is missing      | More conservative (reduces overestimation)          | Can underestimate effects if a term is frequently excluded |
| **Conditional Average** | Averages only across models where the term appears                           | Provides more accurate estimates for included terms | Can overestimate effects if the term is weak but appears in some models |

---

**Which Should You Use?**  
If your goal is prediction or avoiding overestimation, use **full averaging** (safer, more conservative).  
If you are interested in inference and reporting effects, use **conditional averaging**, as it provides a clearer effect size when a term is included.  

## Reporting your regression analyses

When concluding your analysis, it is important to clearly communicate the findings and rationale behind your model choice. Here's what to include:

### Model Selection
Report the **best model** based on AICc, ΔAICc, or any other model selection criteria.
If multiple models are equally good (ΔAICc < 2), discuss **model uncertainty** and therefore the choice to perform model averaging.
If terms are not included in the top model, report their test statistics as they appeared in the global model, but be clear that they were dropped from the top model(s).

### Model Averaging
If you used **model averaging**, specify whether you used the **full average** or **conditional average** and explain the choice (based on whether you prioritize predictive accuracy or effect size estimation).
Report the **model-averaged coefficients**, including the **estimate**, **standard error**, **z-value**, and **p-value** for each significant term. Ensure clarity by highlighting any predictors that were consistently significant across models.
   
### Statistical Significance
Clearly indicate the **significance of each predictor**. Use standard significance thresholds (e.g., p < 0.05) and report any terms that were significant, and discuss  **marginally non-significant** (e.g., p < 0.1) as "trends".
If an interaction term (e.g., `age:sex`) is significant, explain the implications of this interaction for understanding the relationship between the predictors and the response variable.

### Other test statistics
Refer to Table 2 and Table 3 as a guide. 
   
### Model Assumptions
Discuss whether the **assumptions of the model** (normality of residuals, homogeneity of residuals, etc.) were met. If assumptions were violated, describe the steps you took to address them (e.g., log transformations). Typically this is reported in the methods, so as not to clog the results section, which should focus on the answers to your statistical tests around your hypothesis. 

# Generating figures and plots

This section will cover three types of data plots: Linear regression plot with continuous response and predictor variables; scatterplot with boxplots for categorical predictors; stacked barplot for binomial data across categorical predictors. 

Your plots should reflect the data and analyses performed, and should be as transparent as possible by including individual data points, means/medians, error bars.  

Plots use bird_data generated in previous sections

## Linear regression plot

Imagine we are interested in the effect of body size on cognition. 
```{r, message=FALSE, warning=FALSE} 

library(ggplot2)

ggplot(bird_data, aes(x=body_size, y=cognition)) + #specify the data, x and y variables
  geom_point(alpha = 0.7, size = 1.5 ) +  # Add scatterplot points, specify their size, and with slight transparency
  geom_smooth(method=lm, size = 0.5, colour = "black") +  # Add linear regression line with black colour 
  theme_bw() +   theme(panel.grid.major = element_blank(),    # Use a clean black-and-white theme,   # Remove major and minor grid lines, customise axis and border appearance
                       panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),  
                       panel.border = element_rect(linetype = "solid", colour = "black", size=.8)) +
  theme(text=element_text(size=14,  family="sans"),   # Adjust text size and font, enhance axis ticks
        axis.ticks = element_line(colour = "black", size = .7)) +
    labs(x = "Body size (scale mass index)") +   # Set axis labels with meaningful descriptions
  labs(y = "Cognition (trials to criterion)") 
```


We can also depict regression lines for males and females separately by specifying color
```{r, message=FALSE, warning=FALSE} 

library(ggplot2)

ggplot(bird_data, aes(x=body_size, y=cognition, color = sex)) + #specify the data, x and y variables
  geom_point(alpha = 0.7, size = 1.5 ) +  # Add scatterplot points, specify their size, and with slight transparency
  geom_smooth(method=lm, size = 0.8, se = FALSE) +  # Add linear regression lines for both sexes
  scale_color_manual(values = c("male" = "#56B4E9", "female" = "#CC79A7"),#consider colour-blind friendly colours
                     labels = c("Females", "Males")) + # Manually specify legend text
  theme_bw() +   theme(panel.grid.major = element_blank(),    # Use a clean black-and-white theme,   # Remove major and minor grid lines, customise axis and border appearance
                       panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),  
                       panel.border = element_rect(linetype = "solid", colour = "black", size=.8)) +
  theme(text=element_text(size=14,  family="sans"),   # Adjust text size and font, enhance axis ticks
        axis.ticks = element_line(colour = "black", size = .7)) +
    labs(x = "Body size (scale mass index)") +   # Set axis labels with meaningful descriptions
  labs(y = "Cognition (trials to criterion)") 
```

###Saving your plot 

Use the following code to save as a high quality .tif. 
This code will save to the current working directory. Adjust the width and height to suit your plot.   

tiff(file="NAME_OF_YOUR_FILE.tiff", width = 4, height = 4, units = 'in', res = 300)  
ggplot(YOUR_PLOT_CODE)  
dev.off()

## Scatterplot boxplot

Imagine we are interested in the effect of age and sex on cognition. First, we want to calculate some summary statistics about the sample size, mean, error and confidence intervals 

```{r, warning = FALSE, message = FALSE}
library(dplyr)

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

summary_stats <- summarySE(data = bird_data, measurevar = "cognition", groupvars = c("sex", "age"))

summary_stats
```


We apply the mean and error to a boxplot

```{r, warning = FALSE, message = FALSE}
library(ggplot2)

ggplot(bird_data, aes(x = interaction(age, sex), y = cognition, color = age)) +
  geom_point(position = position_jitter(width = 0.2), alpha = 0.7, size = 1) +
  geom_boxplot(alpha = 0.8, outlier.shape = NA) + #outlier.shape = NA otherwise outliers are duplicated data points on plot
  geom_pointrange(data = summary_stats,
                  aes(x = interaction(age, sex), y = cognition, 
                      ymin = cognition - se, 
                      ymax = cognition + se,
                      color =age),
                  colour = "black", size = 0.6) +
  theme_bw() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(colour = "black"),
    panel.border = element_rect(linetype = "solid", colour = "black", linewidth = 0.8),
    legend.title = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 20), # Adjust title size here
    axis.text.x = element_text(angle = 45, hjust = 0.95, vjust = 1.0),
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 24),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14)
  ) +
  labs(
    title = "Cognitive performance in birds",
    x = "",
    y = "Cognition (trials until criterion)"
  ) +
  guides(colour = guide_legend(override.aes = list(size = 16))) +
  scale_color_manual(values = c(
    "#00ABE6", "#EFDD9F", "purple", "#577E43"))
```


Now lets rename the x axis ticks

```{r, warning = FALSE, message = FALSE}
library(ggplot2)

ggplot(bird_data, aes(x = interaction(age, sex), y = cognition, color = age)) +
  geom_point(position = position_jitter(width = 0.2), alpha = 0.7, size = 1) +
  geom_boxplot(alpha = 0.8, outlier.shape = NA) + #outlier.shape = NA otherwise outliers are duplicated data points on plot
  geom_pointrange(data = summary_stats,
                  aes(x = interaction(age, sex), y = cognition, 
                      ymin = cognition - se, 
                      ymax = cognition + se,
                      color =age),
                  colour = "black", size = 0.6) +
  theme_bw() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(colour = "black"),
    panel.border = element_rect(linetype = "solid", colour = "black", linewidth = 0.8),
    legend.title = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 20), # Adjust title size here
    axis.text.x = element_text(angle = 45, hjust = 0.95, vjust = 1.0),
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 24),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14)
  ) + scale_x_discrete(labels = c("Female Adult", "Female Juvenile", "Male Adult", "Male Juvenile")) +
  labs(
    title = "Cognitive performance in birds",
    x = "Sex and Age",
    y = "Cognition (trials until criterion)"
  ) +
  guides(colour = guide_legend(override.aes = list(size = 16))) +
  scale_color_manual(values = c(
    "#00ABE6", "#EFDD9F", "purple", "#577E43"))
```

## stacked barplot

Useful for binomial data

```{r, warning = FALSE, message = FALSE}
ggplot(bird_data, aes(x = interaction(sex, age), fill = factor(correct_choice))) +
  geom_bar(position = "fill") +
  geom_text(aes(label = ..count..), stat = 'count', position = position_fill(vjust = 0.5)) +
  scale_x_discrete(labels = c("Female adult", "female juvenile", "Male adult", "Male juvenile")) +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"), 
        panel.border = element_rect(linetype = "solid", colour = "black", size = 0.8)) +
  scale_fill_manual("Correct choice", values = c("1" = "gray49", "0" = "gray84")) +
  theme(text = element_text(size = 12, family = "sans"),
        axis.ticks = element_line(colour = "black", size = 0.6)) +
  labs(x = "Sex and Age", y = "Proportion of individuals")
```


Lets adjust the naming and legend values 

```{r, warning = FALSE, , message = FALSE}

###rename the values in the column from binary 1 and 0 into words so it's visually more appealing and publishable
bird_data$correct_choice[bird_data$correct_choice == '1'] <- 'Correct'
bird_data$correct_choice[bird_data$correct_choice == '0'] <- 'Incorrect'

ggplot(bird_data, aes(x = interaction(sex, age), fill = factor(correct_choice))) +
  geom_bar(position = "fill") +
  geom_text(aes(label = ..count..), stat = 'count', position = position_fill(vjust = 0.5)) +
 scale_x_discrete(labels = c("Female adult", "female juvenile", "Male adult", "Male juvenile")) +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"), 
        panel.border = element_rect(linetype = "solid", colour = "black", size = 0.8)) +
  scale_fill_manual("Cognition choice", values = c("Correct" = "gray49", "Incorrect" = "gray84")) +
  theme(text = element_text(size = 12, family = "sans"),
        axis.ticks = element_line(colour = "black", size = 0.6)) +
  labs(x = "Sex and Age", y = "Proportion of individuals")
```


And without the interaction between age and sex. 


```{r, warning = FALSE, message = FALSE}

# Rename the values in the column from binary 1 and 0 into words so it's visually more appealing and publishable
bird_data$correct_choice[bird_data$correct_choice == '1'] <- 'Correct'
bird_data$correct_choice[bird_data$correct_choice == '0'] <- 'Incorrect'

ggplot(bird_data, aes(x = sex, fill = factor(correct_choice))) +
  geom_bar(position = "fill") +
  geom_text(aes(label = ..count..), stat = 'count', position = position_fill(vjust = 0.5)) +
  scale_x_discrete(labels = c("Female", "Male")) +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"), 
        panel.border = element_rect(linetype = "solid", colour = "black", size = 0.8)) +
  scale_fill_manual("Cognition choice", values = c("Correct" = "gray49", "Incorrect" = "gray84")) +
  theme(text = element_text(size = 12, family = "sans"),
        axis.ticks = element_line(colour = "black", size = 0.6)) +
  labs(x = "Sex", y = "Proportion of individuals")
```